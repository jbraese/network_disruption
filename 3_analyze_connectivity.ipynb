{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import GOSTnets as gn\n",
    "import networkx as nx\n",
    "import osmnx as ox\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry import box\n",
    "from shapely.wkt import loads\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /home/op/network_manila"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://epsg.io/3123\n",
    "crs_manila = {'init': 'epsg:3123'}\n",
    "crs_global = {'init': 'epsg:4326'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#G_clip = nx.read_gpickle('data_osm_raw/manila_clean_clipped.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_disrupted = nx.read_gpickle('data_osm_raw/manila_clean_disrupted.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare origin and destination points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get administrative boundary of metro manila\n",
    "philippines_adm2 = gpd.read_file(\"boundaries/philippines_adm2.geojson\")\n",
    "philippines_adm2 = philippines_adm2.to_crs({'init':'epsg:4326'})\n",
    "manila = philippines_adm2[philippines_adm2.ADM2_NAME==\"Metropolitan Manila\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manila = manila.to_crs(crs_manila)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exclude laguna area from the manila boundary, as we do not care about trips from within the lake\n",
    "laguna = gpd.read_file(\"boundaries/laguna_de_bay_osm.geojson\")\n",
    "laguna = laguna.to_crs(crs_manila)\n",
    "ax= manila.plot()\n",
    "laguna.plot(ax=ax, color=\"red\", alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manila_nolaguna = gpd.overlay(manila, laguna, how='difference')\n",
    "manila_nolaguna.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_point_grid(gdf, distance, crs):\n",
    "    \"\"\"\n",
    "    this function creates a grid of points with equal distance within the space described by the geodataframe\n",
    "    important: the crs passed as param has to be in accordance with the distance specified\n",
    "    :param gdf: a geodataframe\n",
    "    :param distance: distance between points. measured in crs of gdf\n",
    "    :param crs: the crs in which the distance is measured to return the points\n",
    "    :returns: a geodataframe of points\n",
    "    \"\"\"\n",
    "\n",
    "    gdf_copy = gdf.copy()\n",
    "    gdf_copy = gdf_copy.to_crs(crs)\n",
    "    minx, miny, maxx, maxy = gdf_copy.bounds.values[0]\n",
    "    poly = gdf_copy.unary_union\n",
    "    x = minx\n",
    "    points = []\n",
    "    while x < maxx:\n",
    "        y = miny\n",
    "        while y < maxy:\n",
    "            point = Point(x,y)\n",
    "            #check whether point is within poly and keep only if this is the case\n",
    "            if poly.intersects(point):\n",
    "                points.append(point)\n",
    "            y = y + distance\n",
    "        x = x + distance\n",
    "    df = pd.DataFrame({'geometry':points})  \n",
    "    points_gdf = gpd.GeoDataFrame(df, geometry='geometry', crs=crs)\n",
    "    return points_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_geom = box(121.05, 14.6, 121.1, 14.65)\n",
    "df = pd.DataFrame({\"geometry\":box_geom}, index=[0])\n",
    "box_gdf = gpd.GeoDataFrame(df, geometry='geometry', crs=crs_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create point grid\n",
    "origin_points = create_point_grid(manila_nolaguna, distance = 500, crs = crs_manila)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_points = origin_points.to_crs(crs_global)\n",
    "manila = manila.to_crs(crs_global)\n",
    "laguna = laguna.to_crs(crs_global)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospitals = gpd.read_file(r\"asset_data/MetroManila/MetroManila/DOH/HealthFacilities.shp\")\n",
    "schools = gpd.read_file(r\"asset_data/MetroManila/MetroManila/DepEd/SchoolLocation.shp\")\n",
    "\n",
    "#hospitals = hospitals[hospitals.intersects(box_gdf.unary_union)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = origin_points.plot()\n",
    "hospitals.plot(ax = ax, color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bind points to graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origins_snapped = gn.pandana_snap(G_disrupted, \n",
    "                                  origin_points, \n",
    "                                  source_crs='epsg:4326',\n",
    "                                  target_crs='epsg:3123', \n",
    "                                  add_dist_to_node_col = True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospitals_snapped = gn.pandana_snap(G_disrupted, \n",
    "                                  hospitals, \n",
    "                                  source_crs='epsg:4326',\n",
    "                                  target_crs='epsg:3123', \n",
    "                                  add_dist_to_node_col = True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools_snapped = gn.pandana_snap(G_disrupted, \n",
    "                                  schools, \n",
    "                                  source_crs='epsg:4326',\n",
    "                                  target_crs='epsg:3123', \n",
    "                                  add_dist_to_node_col = True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origins_snapped.to_csv(\"asset_data/origins_snapped.csv\")\n",
    "hospitals_snapped.to_csv(\"asset_data/hospitals_snapped.csv\")\n",
    "schools_snapped.to_csv(\"asset_data/schools_snapped.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origins_snapped = pd.read_csv(\"asset_data/origins_snapped.csv\", dtype = {\"NN\":\"str\", \"NN_dist\": \"float64\"})\n",
    "hospitals_snapped = pd.read_csv(\"asset_data/hospitals_snapped.csv\", dtype = {\"NN\":\"str\", \"NN_dist\": \"float64\"})\n",
    "schools_snapped = pd.read_csv(\"asset_data/schools_snapped.csv\", dtype = {\"NN\":\"str\", \"NN_dist\": \"float64\"})\n",
    "\n",
    "\n",
    "origins_snapped['geometry'] = origins_snapped['geometry'].apply(loads)\n",
    "hospitals_snapped['geometry'] = hospitals_snapped['geometry'].apply(loads)\n",
    "schools_snapped['geometry'] = schools_snapped['geometry'].apply(loads)\n",
    "\n",
    "origins_snapped = gpd.GeoDataFrame(origins_snapped, \n",
    "                                   geometry=\"geometry\", crs = crs_global)\n",
    "hospitals_snapped = gpd.GeoDataFrame(hospitals_snapped, \n",
    "                                   geometry=\"geometry\", crs = crs_global)\n",
    "schools_snapped = gpd.GeoDataFrame(schools_snapped, \n",
    "                                   geometry=\"geometry\", crs = crs_global)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate origin, destination matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quickfix_dtypes(list):\n",
    "    \n",
    "    #when saving and re-importing the snapped points as csv, the data types get messed up\n",
    "    # this is the case because the IDs of the Graph nodes can have either ints or str as IDs\n",
    "    # if they are strings, then they start with \"new_obj\", else they are an integeÃŸ number\n",
    "\n",
    "    #this is likely a relic of gn.simplify_junctions -> address at some point\n",
    "    \n",
    "    \n",
    "    list_copy = list.copy()\n",
    "    list_return = []\n",
    "    for entry in list_copy:\n",
    "        if entry.startswith(\"new_obj\"):\n",
    "            list_return.append(str(entry))\n",
    "        else:\n",
    "            list_return.append(int(entry))\n",
    "            \n",
    "    return list_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_OD_with_startend(G, origins_gdf, destinations_gdf, walk_speed = (4.5/3.6),\n",
    "                               fail_value = 999999999, weight_column = 'time', weighted_origins = False):\n",
    "    \"\"\"\n",
    "    this function wraps around gn.calculate_OD and adds times to walk from the origin point to the first node\n",
    "    and from the last node to the destination (off-network)    \n",
    "    :param G: a graph object\n",
    "    :param origins_gdf: the output of binding a list of origin points to G using gn.pandana_snap with\n",
    "            parameter add_dist_to_node_col = True\n",
    "    :param destinations_gdf: the output of binding a list of destination points to G using gn.pandana_snap\n",
    "            with parameter add_dist_to_node_col = True\n",
    "    :param walk_speed: a number, the speed at which to walk off-network. has to be in unit corrseponding to the\n",
    "            Graphs \"time\" column used by gn.panadana_snap\n",
    "    :param fail_value: a number, fail value passed to gn.calculate_OD\n",
    "    :param weight_column: a string, weight_column passed to gn.calculate_OD\n",
    "    :param weighted_origins: boolean, weighted_origins value passed to gn.calculate_OD\n",
    "\n",
    "    :returns: a OD matrix (as numpy matrix) containing the distance from origin points (rows) to destination points (columns)\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    #convert origins and destinations to list of nodes\n",
    "    origin_nodes = quickfix_dtypes(list(origins_gdf.NN))\n",
    "    destination_nodes = quickfix_dtypes(list(destinations_gdf.NN))\n",
    "    \n",
    "    #calculate OD matrix between start and end nodes, in unit of \"time\"\n",
    "    OD = gn.calculate_OD(G, origins= origin_nodes, destinations = destination_nodes, \n",
    "                         fail_value = fail_value, weight = weight_column, \n",
    "                         weighted_origins = weighted_origins)\n",
    "\n",
    "    ## add time to walk from origin point to nearest node\n",
    "    distance_to_node = np.asarray(origins_gdf.NN_dist)[:, np.newaxis]\n",
    "    time_to_node = distance_to_node * walk_speed\n",
    "    #each row of OD matrix is from same origin, so we can just use numpy's broadcasting\n",
    "    OD = OD + time_to_node\n",
    "    \n",
    "    ## add time to walk from destination node to POI\n",
    "    distance_from_node = np.asarray(destinations_gdf.NN_dist)[:, np.newaxis]\n",
    "    time_from_node = distance_from_node * walk_speed\n",
    "    #each column of OD matrix is same destination, so we transpose times and then add using numpy's broadcasting\n",
    "    OD = OD + time_from_node.T\n",
    "    \n",
    "    return OD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OD for hospital trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OD_hospitals = calculate_OD_with_startend(G_disrupted, origins_snapped, hospitals_snapped, \n",
    "                                walk_speed = 4.5/3.6, fail_value = 999999999, weight_column = 'time', \n",
    "                                weighted_origins = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OD_hospitals_disrupted = calculate_OD_with_startend(G_disrupted, origins_snapped, hospitals_snapped, \n",
    "                                walk_speed = 4.5/3.6, fail_value = 999999999, weight_column = 'time_disrupted', \n",
    "                                weighted_origins = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "OD_hospitals.shape , OD_hospitals_disrupted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_distance_hospitals = np.min(OD_hospitals, axis = 1)\n",
    "min_distance_hospitals_disrupted = np.min(OD_hospitals_disrupted, axis = 1)\n",
    "\n",
    "origin_points['min_hospital_distance_seconds'] = min_distance_hospitals\n",
    "origin_points['min_hospital_distance_seconds_disrupted'] = min_distance_hospitals_disrupted\n",
    "\n",
    "#replace fail values with NAN\n",
    "\n",
    "#replace fail values with NAN\n",
    "origin_points.loc[origin_points['min_hospital_distance_seconds'] > 99999999, \n",
    "                  'min_hospital_distance_seconds'] = np.NaN\n",
    "\n",
    "origin_points.loc[origin_points['min_hospital_distance_seconds_disrupted'] > 99999999, \n",
    "                  'min_hospital_distance_seconds_disrupted'] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OD for school trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OD_schools = calculate_OD_with_startend(G_disrupted, origins_snapped, schools_snapped, \n",
    "                                walk_speed = 4.5/3.6, fail_value = 999999999, weight_column = 'time', \n",
    "                                weighted_origins = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OD_schools_disrupted = calculate_OD_with_startend(G_disrupted, origins_snapped, schools_snapped, \n",
    "                                walk_speed = 4.5/3.6, fail_value = 999999999, weight_column = 'time_disrupted', \n",
    "                                weighted_origins = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OD_schools.shape , OD_schools_disrupted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_distance_schools = np.min(OD_schools, axis = 1)\n",
    "min_distance_schools_disrupted = np.min(OD_schools_disrupted, axis = 1)\n",
    "\n",
    "origin_points['min_school_distance_seconds'] = min_distance_schools\n",
    "origin_points['min_school_distance_seconds_disrupted'] = min_distance_schools_disrupted\n",
    "\n",
    "#replace fail values with NAN\n",
    "origin_points.loc[origin_points['min_school_distance_seconds'] > 99999999, \n",
    "                  'min_school_distance_seconds'] = np.NaN\n",
    "\n",
    "origin_points.loc[origin_points['min_school_distance_seconds_disrupted'] > 99999999, \n",
    "                  'min_school_distance_seconds_disrupted'] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_points[\"increase_hospital_sec\"] = (origin_points[\"min_hospital_distance_seconds_disrupted\"] -\n",
    "                                          origin_points[\"min_hospital_distance_seconds\"])\n",
    "origin_points[\"increase_hospital_perc\"] = (origin_points[\"increase_hospital_sec\"] /\n",
    "                                           origin_points[\"min_hospital_distance_seconds\"])*100\n",
    "\n",
    "\n",
    "\n",
    "hospitaltrip_possible = (origin_points['min_hospital_distance_seconds'].isnull()==False)\n",
    "hospitaltrip_impossible_afterdisrupt = (origin_points['min_school_distance_seconds_disrupted'].isnull()==True)\n",
    "origin_points[\"hospitaltrip_impossible_onlyafterdisrupt\"] = np.where(\n",
    "    (hospitaltrip_possible&hospitaltrip_impossible_afterdisrupt), 1, 0)\n",
    "\n",
    "\n",
    "\n",
    "origin_points[\"increase_school_sec\"] = (origin_points[\"min_school_distance_seconds_disrupted\"] -\n",
    "                                        origin_points[\"min_school_distance_seconds\"])\n",
    "origin_points[\"increase_school_perc\"] = (origin_points[\"increase_school_sec\"] /\n",
    "                                        origin_points[\"min_school_distance_seconds\"])*100\n",
    "\n",
    "schooltrip_possible = (origin_points['min_school_distance_seconds'].isnull()==False)\n",
    "schooltrip_impossible_afterdisrupt = (origin_points['min_school_distance_seconds_disrupted'].isnull()==True)\n",
    "origin_points[\"schooltrip_impossible_onlyafterdisrupt\"] = np.where(\n",
    "    (schooltrip_possible&schooltrip_impossible_afterdisrupt), 1, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_points.to_file(\"asset_data/origin_points_results.geojson\", driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#as csv\n",
    "origin_points.to_csv(\"asset_data/origin_points_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also move to outputfolder\n",
    "origin_points.to_file(\"output/origin_points_results.geojson\", driver='GeoJSON')\n",
    "origin_points.to_csv(\"output/origin_points_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
